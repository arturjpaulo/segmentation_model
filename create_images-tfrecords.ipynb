{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fad50821",
   "metadata": {},
   "source": [
    "# Create_images_tfrecords\n",
    "Script aims to retrievevhead CT images from S3, pre-process them and create tf records files for each subject. The output tf files contain master_image,c1,c2,c3,id_sub. The c1,c2,c3 masks correspond to gray matter, white matter and liquour segmentation carried out on CTseg. 'id_sub' corresponds to subject id_number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbccf5b",
   "metadata": {},
   "source": [
    "### import packages\n",
    "Important: This scripts uses the some processes steps contained in ImagePreparation from DeepCTE3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9d2d568",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import SimpleITK as sitk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import boto3\n",
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "os.chdir('/volumed/proadi.neuro.deepcte3d/main')\n",
    "\n",
    "from model.src.data_utils.preparation3D import ImagePreparation\n",
    "from model.src.data_utils.read_write_images import SingletonReadWriteImages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d00d46a",
   "metadata": {},
   "source": [
    "### Get AWS access keys to retrieve images from bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67cba3c7-8e89-4ed7-b576-6589b543045e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# aws_access_key_id = ''\n",
    "# aws_secret_access_key = ''\n",
    "# aws_session_token = ''\n",
    "\n",
    "\n",
    "\n",
    "aws_access_key_id = 'ASIAZD7L6DI6FXCWYNX2'\n",
    "aws_secret_access_key = 'TqITbLcBv2tINDOkHnng8XFLAxbSf3t8zCKvHnVV'\n",
    "aws_session_token = 'IQoJb3JpZ2luX2VjEC0aCWV1LXdlc3QtMSJIMEYCIQCY+RDmgueJH4W+ZcpFHFPMWfC0pMYALY5YamMCptmvDQIhANavGiaJwq7wba3xu/8iqoa50rDm+be5MIGWm4wJn7z6KpwDCBUQBBoMNjI3MDIzMTU3ODIwIgxCgQIwYXxT1DQXPLkq+QKQxlmBdm1jmQm6YwoAqCf0tShNsczuMDakZ92HiD2wugrHZLEegHltzDOQsagAuVDWj/4lv8U7bvP+A+327CXkwfvTL/ggOwW15jaKxvD9Rq5oZSPDYZzIvDn7HMx5enzqjm6WnDHzScrwk9aT78m8q8ZDBc7W0pvBVCeKiM12y882LBrpVgSzTAG2DWJ4fG92GoNFV6nCAwBwKNuU875M2JTzwYuaUiLmFyA4RiLezevxbOrT+MIEy+tTM5PGgB+mMqbRmKXfD1aColBTxSublsr8hhkXExzWuEwUapI+MtDGeX3F+4lJbfah7kzF0FJah0sbMljm1OHsga35rtJxv/8w8gk3JxFiyvL5cOWWpla6yrjLb+pYYyK5Hm63lEhD9r0KJ35EzqcX3w5cjqwCIPmyOjuwhu+zZUy3RC7IajH+ZkTjk0fdWSj6OwMC/tNqr/pifwOcWbultcYKdqg21CWj0dpC/LFNpVyieJXo3L+T/iFdLhEPMTD0zLWhBjqlAU6kmfCJy36f6hXyPttVMdFlmD9wSpm7mUhiNHJLrRiC9qW8dhDKER4XbHURbTix/zAAgom8r0j5NmI2f+4iCo/btbbX/i2BJyIf6ApwtnlZo64iie2CkZft4zcA/uZiD/YgRaS9Mkkoj67+GwhIMhnwI61cAIIoKoB1Lo1kVYuiZJAr/ODDJ0bjgxXtuIIhP3sPy4Ij24GTyi9uJe0tzZUT9MD2YA=='\n",
    "\n",
    "\n",
    "\n",
    "s3 = boto3.client('s3', aws_access_key_id=aws_access_key_id,\n",
    "                  aws_secret_access_key=aws_secret_access_key,\n",
    "                  aws_session_token=aws_session_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39049358",
   "metadata": {},
   "source": [
    "### Defyning the pre-processing functions\n",
    "\n",
    "This includes reading, writing , resampling and reorienting images using SimpleITK,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c40b5e0-2682-46f2-a440-f1bb42b76563",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_mask_image(input_image, new_size):\n",
    "    \"\"\"Resample mask image using NearestNeighbor funtion. The 'new_size' must be a truple.\"\"\" \n",
    "    resample_filter = sitk.ResampleImageFilter()\n",
    "    # sets the parameters for the resample filter\n",
    "    #para mascara Ã© nearstneighbor\n",
    "    resample_filter.SetInterpolator(sitk.sitkNearestNeighbor)\n",
    "    resample_filter.SetOutputDirection(input_image.GetDirection())\n",
    "    resample_filter.SetOutputOrigin(input_image.GetOrigin())\n",
    "    resample_filter.SetSize(new_size)\n",
    "    # gets the original size and spacing of the image\n",
    "    orig_size = np.array(input_image.GetSize(), dtype=int)\n",
    "    orig_spacing = np.array(input_image.GetSpacing())\n",
    "    # calculates the new spacing\n",
    "    new_spacing = orig_size * (orig_spacing / new_size)\n",
    "    # sets the new spacing to the new image\n",
    "    resample_filter.SetOutputSpacing(new_spacing)\n",
    "    # resamples the cropped image based on a new size desired\n",
    "    new_image = resample_filter.Execute(input_image)\n",
    "    #volume = sitk.GetArrayFromImage(new_image)\n",
    "    volume=(new_image)>=0.5\n",
    "\n",
    "    return volume\n",
    "def read_image_nii(image_path):\n",
    "    \"\"\"Reads nii image.\"\"\" \n",
    "    master_image = sitk.ReadImage(image_path)\n",
    "    return master_image\n",
    "\n",
    "\n",
    "\n",
    "def reorient_image(input_image):\n",
    "    \"\"\"Reorients image to LAS orientation\"\"\" \n",
    "    orientation_filter = sitk.DICOMOrientImageFilter()\n",
    "    orientation_filter.GetDesiredCoordinateOrientation()\n",
    "    orientation_filter.SetDesiredCoordinateOrientation(\"LAS\")\n",
    "    new_image=orientation_filter.Execute(input_image)\n",
    "    return new_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3effc5",
   "metadata": {},
   "source": [
    "### Define TFRecords helper functions\n",
    "Included data serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a1501c03-1b34-49cd-a8e2-fca6f055fce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### tranform np.array data to series\n",
    "def serialize_array(array):  \n",
    "    \n",
    "    array = tf.io.serialize_tensor(array)  \n",
    "    return array\n",
    "\n",
    "def _bytes_feature(value):   \n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"  \n",
    "    value = serialize_array(value)   \n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        \n",
    "        # if value ist tensor       \n",
    "        value = value.numpy()\n",
    "        # get value of tensor  \n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value.encode()]))\n",
    "\n",
    "\n",
    "def create_tfrecord(master_image,c1,c2,c3,sub,age,sex):\n",
    "    feature_exame = {\n",
    "        \"master_image\": _bytes_feature(master_image),\n",
    "        \"c1\": _bytes_feature(c1),\n",
    "        \"c2\": _bytes_feature(c2),\n",
    "        \"c3\": _bytes_feature(c3),\n",
    "        \"sub\": bytes_feature(sub),\n",
    "        \"age\": bytes_feature(age),\n",
    "        \"sex\": bytes_feature(sex)\n",
    "    }\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature_exame))\n",
    "                            \n",
    "def parse_tfrecord_fn(example):\n",
    "    feature_description = {\n",
    "        \"master_image\": tf.io.FixedLenFeature([]),\n",
    "        \"c1\": tf.io.FixedLenFeature([]),\n",
    "        \"c2\": tf.io.FixedLenFeature([]),\n",
    "        \"c3\": tf.io.FixedLenFeature([]),\n",
    "        \"sub\": tf.io.FixedLenFeature([]),\n",
    "        \"age\": tf.io.FixedLenFeature([]),\n",
    "        \"sex\": tf.io.FixedLenFeature([])\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, feature_description)\n",
    "\n",
    "    return example\n",
    "                        \n",
    "                            \n",
    "                      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97469dd7",
   "metadata": {},
   "source": [
    "### Defyning paths in wich images will be downloaded and saved temporary      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ee7d2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name1='backup-neuro'\n",
    "bucket_name2='validacao-retrospectiva-neuro-new'\n",
    "local_folder='masks_retrospectiva'\n",
    "\n",
    "#paths to sabe the image\n",
    "out_path_master='/volumed/Artur2/master/'\n",
    "out_path_mask_c1='/volumed/Artur2/mask_c1/'\n",
    "out_path_mask_c2='/volumed/Artur2/mask_c2/'\n",
    "out_path_mask_c3='/volumed/Artur2/mask_c3/'\n",
    "\n",
    "\n",
    "#paths to save the images into tfrecords\n",
    "tfrecords_dir= '/volumed/Artur2/tf_recods_files'\n",
    "\n",
    "# dataframe containg age information\n",
    "df = pd.read_csv('/volumed/Artur2/summary_metrics_all.csv', sep=';')\n",
    "\n",
    "if not os.path.exists(tfrecords_dir):\n",
    "    os.makedirs(tfrecords_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42740ca8",
   "metadata": {},
   "source": [
    "### List of IDs that will be pre-processed and saved to TF recods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "626a8e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "327"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_sub = open(\"/volumed/Artur2/norm_inter.txt\", \"r\")\n",
    "id_sub=id_sub.read()\n",
    "id_sub = id_sub.split(\"\\n\")\n",
    "\n",
    "len(id_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44a3eb3",
   "metadata": {},
   "source": [
    "### Sequential pre-processing\n",
    "includes: Downloading images, reading, pre-processing and saving to TF records.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac27167a-31e9-4f1d-9fe5-4261cc8711bc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "M\n",
      "Gerou file_id_02d276e6-6098a27e-a4356652-2cb72017-2d87c943\n",
      "10\n",
      "M\n",
      "Gerou file_id_02e28174-35655600-f3d077ff-bdda3f6b-5309fdbb\n",
      "erro em id_0419e964-21cae926-527958ef-7d04a52c-a6db45ec\n",
      "list index out of range\n",
      "erro em id_04a5e8ba-a8061b5c-329c0e26-57f1fab0-4da9aac5\n",
      "list index out of range\n",
      "26\n",
      "F\n",
      "Gerou file_id_04afa275-637ab3de-6803925f-b90ff9fa-6e5d1718\n",
      "14\n",
      "M\n",
      "Gerou file_id_072d0261-f6ddffba-34c63613-c26d3a20-105f849f\n",
      "24\n",
      "F\n",
      "Gerou file_id_07506002-da753ed7-93754b80-c92f13b8-8907963e\n",
      "13\n",
      "F\n",
      "Gerou file_id_081488e8-b609d3f1-a6019bf7-4c794556-a419607b\n",
      "36\n",
      "F\n",
      "Gerou file_id_0837f08a-6a487669-0145be63-b7a3443c-4a4aa8dc\n",
      "36\n",
      "F\n",
      "Gerou file_id_083858f8-313beb49-3b92dfae-e132f5f7-48572424\n",
      "25\n",
      "F\n",
      "Gerou file_id_086a8507-9d3e4375-c6db8800-a176cfad-01a4743d\n",
      "22\n",
      "M\n",
      "Gerou file_id_09b792e0-d2daebc5-f959f65a-ae8a1343-ad3dbebf\n",
      "erro em id_0a9dd9f7-f3023233-2b842f14-59949f9c-525a970a\n",
      "list index out of range\n",
      "14\n",
      "M\n",
      "Gerou file_id_0ab4bf38-60dcd31a-31b602a8-fdb9b9e7-9f4cb036\n",
      "42\n",
      "F\n",
      "Gerou file_id_0bc6f8f8-e457d28f-28e732d3-32522761-6b970523\n",
      "8\n",
      "M\n",
      "Gerou file_id_0d097065-d02daab9-482762a0-b8eba4e1-b94cba1c\n",
      "51\n",
      "F\n",
      "Gerou file_id_0f29aaf3-5c21b7f1-bf05c8c0-7e3b7b9e-45be3752\n",
      "31\n",
      "F\n",
      "Gerou file_id_0f3d2d91-7d34ec62-a2f9ac62-0692c058-0b45e375\n",
      "21\n",
      "F\n",
      "Gerou file_id_0f8c34c7-63a51ec3-46ece178-784ab0eb-52fcafb1\n",
      "43\n",
      "F\n",
      "Gerou file_id_0fd64862-a35e6180-2aac1b32-2061c709-6163fef3\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Image size\n",
    "x_dim=256\n",
    "y_dim=256\n",
    "z_dim=256\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "for patient_id in id_sub[:20]:\n",
    "    \n",
    "    \n",
    "    remote_path_masks='segmented_masks_artur/' + patient_id + '.zip'\n",
    "    \n",
    "    remote_path_master='master_images_base_normativa/' + patient_id + '.zip'\n",
    "    \n",
    "    \n",
    "    local_path_masks='/volumed/Artur2/masks_retrospectiva/' + patient_id + '.zip'\n",
    "    local_path_master='/volumed/Artur2/masters_retrospectiva/' + patient_id + '.zip'\n",
    "    \n",
    "    try:\n",
    "            \n",
    "        #downloading images\n",
    "        \n",
    "        s3.download_file(bucket_name2, remote_path_masks, local_path_masks)        \n",
    "        s3.download_file(bucket_name2, remote_path_master, local_path_master)\n",
    "\n",
    "        with zipfile.ZipFile(local_path_masks, 'r') as zip_ref:\n",
    "        \n",
    "            zip_ref.extractall(local_path_masks[:-4])      \n",
    "        os.remove(local_path_masks)\n",
    "\n",
    "        with zipfile.ZipFile(local_path_master, 'r') as zip_ref:\n",
    "            zip_ref.extractall(local_path_master[:-4])      \n",
    "        os.remove(local_path_master)\n",
    "\n",
    "\n",
    "        #removing .zip extension\n",
    "        local_path_masks=local_path_masks[:-4]\n",
    "        local_path_master=local_path_master[:-4]\n",
    "\n",
    "        #preprocessing master image\n",
    "        image_io = SingletonReadWriteImages()\n",
    "\n",
    "        master_image=(glob.glob(local_path_master +'/id*/nii*/master_image.nii.gz')[0])\n",
    "\n",
    "\n",
    "\n",
    "        master_image=read_image_nii(master_image)\n",
    "        \n",
    "        #Using ImagePreparation module to pre-process master images \n",
    "\n",
    "        image_processed = ImagePreparation(master_image=master_image,\n",
    "                                               window_level=-15,\n",
    "                                               window_width=100,\n",
    "                                               image_size=256,\n",
    "                                               reorient=False)\n",
    "\n",
    "        itkimage = image_processed.loadITK(resample=True)\n",
    "        \n",
    "        #Reorient images to LAS \n",
    "        image_reo= reorient_image(itkimage)\n",
    "\n",
    "\n",
    "        #preprocess the masks: reorient and resample\n",
    "        c1=image_io.read_image_nii(glob.glob(local_path_masks+'/nii*/c01_1_00001_temp_master_image_CTseg.nii.gz')[0])\n",
    "        c1=reorient_image(c1)\n",
    "        c1=resample_mask_image(c1,(256,256,256))\n",
    "\n",
    "        c2=image_io.read_image_nii(glob.glob(local_path_masks+'/nii*/c02_1_00001_temp_master_image_CTseg.nii.gz')[0])\n",
    "        c2=reorient_image(c2)\n",
    "        c2=resample_mask_image(c2, (256,256,256))\n",
    "\n",
    "        c3=image_io.read_image_nii(glob.glob(local_path_masks+'/nii*/c03_1_00001_temp_master_image_CTseg.nii.gz')[0])\n",
    "        c3=reorient_image(c3)\n",
    "        c3=resample_mask_image(c3, (256,256,256))\n",
    "        \n",
    "        \n",
    "        #Transforming images into np.arrays\n",
    "        c1_matrix=(sitk.GetArrayFromImage(c1))\n",
    "        c2_matrix=(sitk.GetArrayFromImage(c2))\n",
    "        c3_matrix=(sitk.GetArrayFromImage(c3))\n",
    "        img_processed = sitk.GetArrayFromImage(image_reo)\n",
    "        \n",
    "\n",
    "            \n",
    "        \n",
    "        \n",
    "        age = df.loc[df['patient_ID'] == patient_id, 'age'].values\n",
    "        \n",
    "        age=str(age[0])\n",
    "        \n",
    "        sex=df.loc[df['patient_ID'] == patient_id, 'patient_sex'].values\n",
    "\n",
    "        sex=str(sex[0].strip())\n",
    "        \n",
    "        print(age)\n",
    "        print(sex)\n",
    "        #saving to TF records\n",
    "        with tf.io.TFRecordWriter(tfrecords_dir + \"/file_%s.tfrec\" % patient_id) as writer:\n",
    "            example = create_tfrecord(img_processed, c1_matrix, c2_matrix, c3_matrix, patient_id,age,sex)\n",
    "            writer.write(example.SerializeToString())\n",
    "            print(\"Gerou file_%s\" % patient_id)\n",
    "        \n",
    "        \n",
    "    except Exception as erro:\n",
    "        print('erro em',patient_id)\n",
    "        shutil.rmtree(local_path_master +'/')\n",
    "        shutil.rmtree(local_path_masks+'/')\n",
    "        print (erro)\n",
    "\n",
    "\n",
    "print(\"Done\")     \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fb0672",
   "metadata": {},
   "source": [
    "### Scrap paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726c60a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/volumed/Artur2/summary_metrics_all.csv', sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfce17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b302d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_sub[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5115f329",
   "metadata": {},
   "outputs": [],
   "source": [
    "for patient_id in id_sub[:10]:\n",
    "    \n",
    "\n",
    "    age = df.loc[df['patient_ID'] == patient_id, 'age'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96aa75f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "int(age)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c26d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /volumed/Artur2/tf_recods_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e3a283",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -r file*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36efca02",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b88bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
